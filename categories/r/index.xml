<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R | Antti Kuusinen</title>
    <link>/categories/r/</link>
      <atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    <description>R</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>©2020</copyright><lastBuildDate>Wed, 22 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>R</title>
      <link>/categories/r/</link>
    </image>
    
    <item>
      <title>On the data analysis of perceptual matching of concert hall acoustics</title>
      <link>/post/2020-01-22-onanalysisofchmdata/2020-01-22-onanalysisofchmdata/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-01-22-onanalysisofchmdata/2020-01-22-onanalysisofchmdata/</guid>
      <description>


&lt;!-- % This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;http://rmarkdown.rstudio.com&gt;. --&gt;
&lt;!-- When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: --&gt;
&lt;p&gt;In this post I will briefly discuss and illustrate the analysis of perceptual matching experiment on concert hall acoustics. How the sound samples / auralizations of concert hall acoustics in this experiment were made is a topic of another time.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(This presentation is prepared for and presented in the “Acoutect Research and Demonstrator Workshop 5” held at Aalto University in 20-24 January 2020)&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The background of the experiment is on our previous research on concert hall acoustics with the loudspeaker orchestra and spatial sound / multichannel auralization techniques that we have conducted at Aalto Uni. over the past decade or so. There are always some ideas left in old notebooks that did not get studied at the time they emerged and this perceptual matching experiment is one of those.&lt;/p&gt;
&lt;p&gt;The premise and the guiding idea in many of our previous works has been the ability to discern, evaluate and analyse even the tinyest differences and the different flavors and nuances of concert hall acoustics. Thus, previously most of our perceptual studies have been conducted so that the differences between different halls would be as easy to perceive as possible. One of the best ways to reveal small differences in room acoustics is to play back the music (signal) continuously so that when the sample is switched to another hall, only the surrounding acoustics changes while the music goes on and on. &lt;!--(As any one who have participated in listening experiments or perform critical listening knows, also looping back a short segment of sound and quickly switching back and forth between different samples is often a very revealing strategy to pinpoint small differences and nuances in sounds.)--&gt;&lt;/p&gt;
&lt;p&gt;However, the acoustic “teleportation” is only possible at the lab, and in natural environments we may perceptually evaluate the acoustical characteristics and differences between spaces only by physically moving from one place to another, for instance, from concert hall to concert hall. And aside from research projects, seldom exactly the same sounds are listened to, but commonly our perceptions and assessments of room acoustical qualities are based on the experience of different sounds in the different rooms.&lt;/p&gt;
&lt;p&gt;So here we simply asked that &lt;em&gt;are people able to detect and match concert halls when they are listening to same or different excitation signals?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So, in this experiment the listener is presented with a sound that is auralized to a particular concert hall (reference), and then she/he needs to find the same concert hall among four alternatives with different or same sound auralized in those halls. Listener is also presented with the same sounds to enable comparison of performance between the different and same sounds. The experiment was implemented in Matlab. Here is a figure of the GUI:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../img/match.png&#34; width=&#34;50%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The experiment is constructed with the following variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Four concert halls coded as “AC”, “BP”, “CP”, “MH”.
&lt;ul&gt;
&lt;li&gt;Each one acts as the reference in each sound case&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;MUSIC: Full orchestra
&lt;ul&gt;
&lt;li&gt;Two excerpts (7 s) from the same piece by Beethoven -&amp;gt; “BEE1” and “BEE2”&lt;/li&gt;
&lt;li&gt;Combinations:
&lt;ul&gt;
&lt;li&gt;same sounds: BEE1 vs BEE1; BEE2 vs BEE2&lt;/li&gt;
&lt;li&gt;different sounds: BEE1 vs BEE2; BEE2 vs BEE1&lt;/li&gt;
&lt;li&gt;each hall acts as a ref -&amp;gt; 4*4 = 16 trials&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;INSTR: Single violin
&lt;ul&gt;
&lt;li&gt;Single sounds and short passages (&amp;lt; 6 s)&lt;/li&gt;
&lt;li&gt;Combinations:
&lt;ul&gt;
&lt;li&gt;same: i.e., Violin 1 vs Violin 1 (8 trials)&lt;/li&gt;
&lt;li&gt;different: i.e., Violin 1 vs Violin 2 (8 trials)&lt;/li&gt;
&lt;li&gt;Note that these are single intrument sounds and it does not make much sense to do Violin 2 vs Violin 2, as it would be basically the same as Violin 1 vs Violin 1.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;NOTE: Matching is done only within MUSIC or INSTR sounds, meaning that Beethoven is not compared to Violin sounds or vice versa.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, in order to make this experiment a little more robust,&lt;/p&gt;
&lt;p&gt;We would have liked to include one repetition of each of the trials, but because this experiment was scheduled to be run in a single afternoon with approx. 15 people, the experiment should not take more than 30 min to complete and it was necesssary to sacrifice the repetition in order to reduce the final lenght of experiment.&lt;/p&gt;
&lt;div id=&#34;for-the-uninitialized-reading-the-data-from-.csv-files-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;For the uninitialized: Reading the data from .csv files in R&lt;/h3&gt;
&lt;p&gt;In this experiment, I chose to set up Matlab to output the results as .csv files for each listener and then move to R for the data analysis.&lt;/p&gt;
&lt;p&gt;Let’s first have a peak at the data of a single individual:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#  READ SINGLE CSV FILE 
test &amp;lt;- read.csv2(&amp;#39;S01.csv&amp;#39;, sep = &amp;quot;,&amp;quot;)
head(test)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   SUB_ID ORD CASE_ID SOUNDTYPE SOUNDNUM SAMEDIFF MUS_REF MUS_COM REF  A  B  C
## 1    S01   1       1     MUSIC        0     same    BEE1    BEE1  AC CP AC MH
## 2    S01   2       2     MUSIC        0     same    BEE1    BEE1  BP BP AC CP
## 3    S01   3       5     MUSIC        0     diff    BEE1    BEE2  AC BP AC MH
## 4    S01   4      23     INSTR        7     diff  viulut viulut2  MH AC BP CP
## 5    S01   5       3     MUSIC        0     same    BEE1    BEE1  MH MH BP CP
## 6    S01   6      14     MUSIC        0     same    BEE2    BEE2  BP AC BP CP
##    D  ANS CORRECT                 TIME COMPLETED REP
## 1 BP   BP       0 14-Jan-2020 13:34:28         1   1
## 2 MH &amp;lt;NA&amp;gt;       0 13-Jan-2020 15:27:52         0   1
## 3 CP &amp;lt;NA&amp;gt;       0 13-Jan-2020 15:27:52         0   1
## 4 MH &amp;lt;NA&amp;gt;       0 13-Jan-2020 15:27:52         0   1
## 5 AC &amp;lt;NA&amp;gt;       0 13-Jan-2020 15:27:52         0   1
## 6 MH &amp;lt;NA&amp;gt;       0 13-Jan-2020 15:27:52         0   1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So this basically illustrates also the design matrix of the experiment; the different columns hold the variables, for instance, MUS_REF indicates the sound of the REF and MUS_COM that of the comparison samples. SAMEDIFF column indicates whether the MUS_REF and MUS_COM were the same or different sounds. REF and A-D shows the hall names behind the GUI buttond and the column ANS indicates the chosen response and CORRECT indicates whether the answer was correct (1) or not (0).&lt;br /&gt;
(No need to worry about some of the columns, for instance, REP does not mean anything here as there were no repetitions.)&lt;/p&gt;
&lt;p&gt;Then, a set of individual .csv -files can be read and bind to single data.frame as follows (For illustration purposes, now here is only 4 individual .csv files):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# LIST .csv files
csvfiles = list.files(pattern = &amp;#39;.csv&amp;#39;)
# Make an empty list
chm_data &amp;lt;- list();
# Populate the list entries from the .csv-files
for (rfile in 1:length(csvfiles)){
    filename &amp;lt;- csvfiles[rfile]
    chm_data[[rfile]] &amp;lt;- read.csv2(filename, sep = &amp;quot;,&amp;quot;)
} 
# ROW BIND THE LIST ELEMENTS: &amp;quot;UNLIST&amp;quot; (the unlist() -function outputs an atomic vector of all elements and does not work here)
chm_df &amp;lt;- do.call(rbind, chm_data) # 
# CAST AS DATA.FRAME:
chm_df &amp;lt;- data.frame(chm_df)

# not run here
#summary(chm_df)
# SAVE AS TXT:
#write.table(chm_df, file = &amp;#39;LONGTABLE2.txt&amp;#39;, sep = &amp;#39;,&amp;#39;, quote = F)
# OR AS .RData:
#save(chm_df, file = &amp;quot;LONGTABLE2.RData&amp;quot;)

# CHECK data
str(chm_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    192 obs. of  18 variables:
##  $ SUB_ID   : Factor w/ 4 levels &amp;quot;S01&amp;quot;,&amp;quot;S02&amp;quot;,&amp;quot;S03&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ ORD      : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ CASE_ID  : int  1 2 5 23 3 14 4 24 10 8 ...
##  $ SOUNDTYPE: Factor w/ 2 levels &amp;quot;INSTR&amp;quot;,&amp;quot;MUSIC&amp;quot;: 2 2 2 1 2 2 2 1 2 2 ...
##  $ SOUNDNUM : int  0 0 0 7 0 0 0 8 0 0 ...
##  $ SAMEDIFF : Factor w/ 2 levels &amp;quot;diff&amp;quot;,&amp;quot;same&amp;quot;: 2 2 1 1 2 2 2 1 1 1 ...
##  $ MUS_REF  : Factor w/ 3 levels &amp;quot;BEE1&amp;quot;,&amp;quot;BEE2&amp;quot;,..: 1 1 1 3 1 2 1 3 2 1 ...
##  $ MUS_COM  : Factor w/ 4 levels &amp;quot;BEE1&amp;quot;,&amp;quot;BEE2&amp;quot;,..: 1 1 2 4 1 2 1 4 1 2 ...
##  $ REF      : Factor w/ 4 levels &amp;quot;AC&amp;quot;,&amp;quot;BP&amp;quot;,&amp;quot;CP&amp;quot;,..: 1 2 1 4 4 2 3 3 2 3 ...
##  $ A        : Factor w/ 4 levels &amp;quot;AC&amp;quot;,&amp;quot;BP&amp;quot;,&amp;quot;CP&amp;quot;,..: 3 2 2 1 4 1 4 1 3 3 ...
##  $ B        : Factor w/ 4 levels &amp;quot;AC&amp;quot;,&amp;quot;BP&amp;quot;,&amp;quot;CP&amp;quot;,..: 1 1 1 2 2 2 3 3 1 2 ...
##  $ C        : Factor w/ 4 levels &amp;quot;AC&amp;quot;,&amp;quot;BP&amp;quot;,&amp;quot;CP&amp;quot;,..: 4 3 4 3 3 3 2 2 4 1 ...
##  $ D        : Factor w/ 4 levels &amp;quot;AC&amp;quot;,&amp;quot;BP&amp;quot;,&amp;quot;CP&amp;quot;,..: 2 4 3 4 1 4 1 4 2 4 ...
##  $ ANS      : Factor w/ 1 level &amp;quot;BP&amp;quot;: 1 NA NA NA NA NA NA NA NA NA ...
##  $ CORRECT  : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ TIME     : Factor w/ 2 levels &amp;quot;13-Jan-2020 15:27:52&amp;quot;,..: 2 1 1 1 1 1 1 1 1 1 ...
##  $ COMPLETED: int  1 0 0 0 0 0 0 0 0 0 ...
##  $ REP      : int  1 1 1 1 1 1 1 1 1 1 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function &lt;strong&gt;str()&lt;/strong&gt; summarises the variables and their types and so on and it is always worthwhile to check that there no some funny business going on.&lt;/p&gt;
&lt;p&gt;Now, instead of using only 4 individuals, I have simulated random results for 20 individuals, in the hope to better reflect the real data that we are aiming at.&lt;/p&gt;
&lt;p&gt;These simulated results have been saved in “SIMDATA.txt”, which is in the same format as the data.frame generated above.&lt;/p&gt;
&lt;p&gt;This data set will be used in the next steps of this presentation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# First remove variables from workspace
rm(list = ls()) 
# and read the data.table:
simdata &amp;lt;- read.table(&amp;quot;SIMDATA.txt&amp;quot;, sep = &amp;quot;,&amp;quot;, header = T)
# head(simdata)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;preliminaries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;Now that we have our &lt;strong&gt;raw&lt;/strong&gt; dataset ready for analysis, let’s first think little about the objectives of the next steps and what we would like our data to tell us.&lt;/p&gt;
&lt;p&gt;So, we are interested in the following main question:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Are listeners able to match the samples based on the room acoustics of the concert halls and are there differences in performances when they do this with the same and different excitation signals?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This question can then be broken down to different levels:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Overall results (i.e., all same and all different)&lt;/li&gt;
&lt;li&gt;Results between MUSIC (Beethoven) and INSTR (Violin)&lt;/li&gt;
&lt;li&gt;Possible differences between concert halls (i.e.,are some concert halls confused between each other more than others?)&lt;/li&gt;
&lt;li&gt;Results of each individual&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the skinning of any dataset, a good first step is to try to plot the results in some way.&lt;/p&gt;
&lt;p&gt;Here, we will simply calculate the percentages of the correct answer per each individual and then plot the results with ggplot.&lt;/p&gt;
&lt;p&gt;Calculate the percentages and make a corresponding data.frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataf &amp;lt;- c()
ids &amp;lt;- c()
for(s in levels(simdata$SUB_ID)) {
    sdata &amp;lt;- subset(simdata, SUB_ID == s)   # EXTRACT SUBJECT DATA
    ids &amp;lt;- c(ids, s) # KEEP TRACK OF SUB ID
    musvec &amp;lt;- c()   # init
    sdtemp &amp;lt;- c()   # init
    for(ss in levels(sdata$SAMEDIFF)) {         
            samediffdata &amp;lt;- subset(sdata, SAMEDIFF == ss)   # EXTRACT same or diff DATA 
            # GET THE PERCENTAGE OF CORRECT ANS
            sdtemp[ss] &amp;lt;- as.numeric(round(sum(samediffdata$CORRECT)/length(samediffdata$CORRECT), digits = 2))         
            
            mustemp &amp;lt;- c()  # init  
            for(sss in levels(samediffdata$MUS_REF)) {
                musdata &amp;lt;- subset(samediffdata, MUS_REF == sss) # ECTRACT DATA by sound
                mustemp[sss] &amp;lt;- round(sum(musdata$CORRECT)/length(musdata$CORRECT), digits = 2) # GET THE PERCENTAGE OF CORRECT ANS
                names(mustemp)[names(mustemp) == sss] &amp;lt;-  c(paste(musdata$MUS_REF[[1]],&amp;#39;-&amp;#39;,musdata$MUS_COM[[1]], sep = &amp;quot;&amp;quot;)) # KEEP TRACK OF THE COMPARISONS
        }       
        musvec &amp;lt;- c(musvec, mustemp) # POPULATE
    }   
    sdvec &amp;lt;- c(sdtemp, musvec) # POPULATE
    dataf &amp;lt;- rbind(dataf, sdvec) # POPULATE
}
# SOME CLEANING UP AND FINALISING OF THE DATAFRAME:
SAMEDIFF &amp;lt;- data.frame(matrix(as.numeric(dataf[,1:8]),nrow = 20)) 
colnames(SAMEDIFF) &amp;lt;- c(names(sdtemp),names(musvec))
SAMEDIFF &amp;lt;- cbind(ids, SAMEDIFF)
colnames(SAMEDIFF)[1] &amp;lt;- &amp;#39;ID&amp;#39; 
head(SAMEDIFF) # show first 6 rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    ID diff same BEE1-BEE2 BEE2-BEE1 viulut-viulut2 BEE1-BEE1 BEE2-BEE2
## 1  S1 0.04 0.42      0.00      0.12           0.00      0.12      0.75
## 2 S10 0.12 0.29      0.12      0.25           0.00      0.25      0.38
## 3 S11 0.17 0.25      0.38      0.12           0.00      0.25      0.12
## 4 S12 0.33 0.25      0.12      0.50           0.38      0.38      0.25
## 5 S13 0.25 0.17      0.25      0.25           0.25      0.25      0.00
## 6 S14 0.21 0.25      0.25      0.25           0.12      0.38      0.25
##   viulut-viulut
## 1          0.38
## 2          0.25
## 3          0.38
## 4          0.12
## 5          0.25
## 6          0.12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, make a “long”-format table with melt()-function, and plot the results with ggplot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#### BOXPLOTS: OVERALL SAME vs DIFF
library(reshape2) # melt()-function
# melt the data into &amp;quot;long&amp;quot;-format for ggplotting
m0 = melt(SAMEDIFF[,c(&amp;#39;same&amp;#39;,&amp;#39;diff&amp;#39;)],measure.vars = c(&amp;#39;same&amp;#39;, &amp;#39;diff&amp;#39;), variable.name = &amp;#39;G&amp;#39;)

library(ggplot2)

g1 &amp;lt;- ggplot(data = m0, aes(y = value, x = G)) +  theme_bw() + 
  geom_boxplot() +
geom_point(aes(y = value, x = G, shape = G), position = position_jitter(width = 0.2), size = 1, alpha = 1, show.legend = F, color = &amp;#39;grey&amp;#39;) +
coord_cartesian(ylim = c(0,1)) + labs(title =  &amp;#39;&amp;#39;, x = &amp;#39;&amp;#39;, y = &amp;#39;Percentage of correct answers&amp;#39;, size = 0.1, color = &amp;#39;black&amp;#39;) + 
theme(axis.title.y = element_text(size = 8)) + ggtitle(&amp;#39;Overall&amp;#39;)

# FOR SAVING THE PLOT: (not executed)
#ggsave(filename = &amp;#39;SRT_basic_boxplot.eps&amp;#39;, g1, width = 10, height = 6, units = &amp;#39;cm&amp;#39;)

#### BOXPLOTS: MUSIC (Beethoven) vs INSTR (Violin)
m1 = melt(SAMEDIFF[,colnames(SAMEDIFF)[4:9]], measure.vars = colnames(SAMEDIFF)[4:9], variable.name = &amp;#39;musiclist&amp;#39;)

samedifflist &amp;lt;- c(rep(&amp;#39;diff&amp;#39;, 60),rep(&amp;#39;same&amp;#39;, 60))
muslist &amp;lt;- c(rep(&amp;#39;Beethoven&amp;#39;, 40), rep(&amp;#39;Violin&amp;#39;, 20), rep(&amp;#39;Beethoven&amp;#39;, 40), rep(&amp;#39;Violin&amp;#39;, 20))

m1 &amp;lt;- cbind(m1,samedifflist, muslist)

g2 &amp;lt;- ggplot(data = m1, aes(y = value, x = samedifflist,colour = muslist),show.legend = F) + 
theme_bw() + 
geom_boxplot(show.legend = F)+
geom_point(aes(y = value, colour = muslist), position = position_jitter(width = 0.2), size = 0.5, alpha = 0.5, show.legend = F, color = &amp;#39;grey&amp;#39;) +
facet_grid(.~muslist) +
coord_cartesian(ylim = c(0,1)) + labs(title =  &amp;#39;&amp;#39;, x = &amp;#39;&amp;#39;, y = &amp;#39;Percentage of correct answers&amp;#39;, size = 0.1, color = &amp;#39;black&amp;#39;) + 
theme(axis.title.y = element_text(size = 8)) + ggtitle(&amp;#39;Per music&amp;#39;)

library(gridExtra) # for grid.arrange()
grid.arrange(g1,g2,nrow = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/2020-01-22-OnAnalysisOfCHMData/2020-01-22-OnAnalysisOfCHMData_files/figure-html/boxplots-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we have the first view of our data. Note, that as expected with randomised data, the mean percentages of correct answers set nicely on the change level of 1/4 = 25 % as it should be.&lt;/p&gt;
&lt;p&gt;With another dataset, one would be inclined to run a test, such as Kruskal-Wallis rank sum test (non-parametric one way anova by ranks) to test whether the distributions of the percentages of correct answers differ between the same and difference cases. Using the m1-data from above, one may run this e.g., by kruskal.test(x=m1$value, g=m1$samedifflist).&lt;/p&gt;
&lt;p&gt;Now, besides just looking at the correct answers, we can look at the actual perceived halls (ANS column) versus the true (REF column) halls.&lt;/p&gt;
&lt;p&gt;This way the experiment now presents itself as a classical multiclass classification problem, where the listeners makes class “predictions” based on one’s perceptions.&lt;/p&gt;
&lt;p&gt;Therefore, these results are perhaps best presented and analysed in the spirit of machine learning and treated with the tools, concepts and metrics developed for the classification tasks and for the analysis of confusion matrices.&lt;/p&gt;
&lt;div id=&#34;onto-the-confusion-matrices&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Onto the confusion matrices&lt;/h3&gt;
&lt;p&gt;Confusion matrices can be exctracted in quite a straightforward manner from our data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;halls &amp;lt;- levels(simdata$REF)

# OVERALL SAME:
hallmat1 &amp;lt;- matrix(0,nrow = 4, ncol = 4);
rownames(hallmat1) &amp;lt;- halls
colnames(hallmat1) &amp;lt;- halls
samedata &amp;lt;- subset(simdata, SAMEDIFF == &amp;#39;same&amp;#39;)
for(i in 1:nrow(samedata)){
    hallmat1[as.character(samedata$REF[i]), as.character(samedata$ANS[i])] &amp;lt;- hallmat1[as.character(samedata$REF[i]), as.character(samedata$ANS[i])] + 1
}

# OVERALL DIFF: 
hallmat2 &amp;lt;- matrix(0,nrow = 4, ncol = 4);
rownames(hallmat2) &amp;lt;- halls
colnames(hallmat2) &amp;lt;- halls
diffdata &amp;lt;- subset(simdata, SAMEDIFF == &amp;#39;diff&amp;#39;)

for(i in 1:nrow(samedata)){
    hallmat2[as.character(diffdata$REF[i]),as.character(diffdata$ANS[i])] &amp;lt;- hallmat2[as.character(diffdata$REF[i]),as.character(diffdata$ANS[i])] + 1
}

# PER MUSIC, SAME
samemats &amp;lt;- list()
for(s in levels(simdata$MUS_REF)) {
hallmat &amp;lt;- matrix(0,nrow = 4, ncol = 4);
rownames(hallmat) &amp;lt;- halls
colnames(hallmat) &amp;lt;- halls
data &amp;lt;- subset(simdata, SAMEDIFF == &amp;#39;same&amp;#39; &amp;amp; MUS_REF == as.character(s))
    for(i in 1:nrow(data)){
    hallmat[as.character(data$REF[i]),as.character(data$ANS[i])] &amp;lt;- hallmat[as.character(data$REF[i]), as.character(data$ANS[i])] + 1
    }
samemats[[as.character(s)]] &amp;lt;- hallmat
}

# PER MUSIC, DIFF
diffmats &amp;lt;- list()
for(s in levels(simdata$MUS_REF)) {
hallmat &amp;lt;- matrix(0,nrow = 4, ncol = 4);
rownames(hallmat) &amp;lt;- halls
colnames(hallmat) &amp;lt;- halls
data &amp;lt;- subset(simdata, SAMEDIFF == &amp;#39;diff&amp;#39; &amp;amp; MUS_REF == as.character(s))
    for(i in 1:nrow(data)){
    hallmat[as.character(data$REF[i]),as.character(data$ANS[i])] &amp;lt;- hallmat[as.character(data$REF[i]), as.character(data$ANS[i])] + 1
    }
diffmats[[as.character(s)]] &amp;lt;- hallmat
}


# PER MUSIC, MUSIC VS MUSIC:
musmatsS &amp;lt;- list()
for(s in levels(simdata$MUS_REF)) {
    musmatsSS &amp;lt;- list()
    data &amp;lt;- subset(simdata, MUS_REF == as.character(s))
    for(ss in levels(simdata$MUS_COM)) {
        data2 &amp;lt;- subset(data, MUS_COM == as.character(ss))
        hallmat &amp;lt;- matrix(0,nrow = 4, ncol = 4);
        rownames(hallmat) &amp;lt;- halls
        colnames(hallmat) &amp;lt;- halls
    if(nrow(data2) &amp;gt; 0) {
        for(i in 1:nrow(data2)){
        hallmat[as.character(data2$REF[i]),as.character(data2$ANS[i])] &amp;lt;- hallmat[as.character(data2$REF[i]), as.character(data2$ANS[i])] + 1
        }
    }
    musmatsSS[[as.character(ss)]] &amp;lt;- hallmat
    }
musmatsS[[as.character(s)]] &amp;lt;- musmatsSS
}

# Let&amp;#39;s see what we have:
hallmat1 # overall same&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    AC BP CP MH
## AC 39 17 39 25
## BP 24 39 24 33
## CP 31 33 26 30
## MH 26 28 33 33&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#hallmat2 # overall diff (not shown)
#samemats # per music, same (not shown)
#diffmats # per music, diff (not shown)
#musmatsS # per music vs music (not shown)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-with-caret-package&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Analysis with caret-package&lt;/h3&gt;
&lt;p&gt;Now that we have our set of main confusion matrices ready (we won’t be looking at individual level performance here), there a various R packages that can be used for the analysis. Here, we will be using the caret -package, and as an example, we will analyse only a single matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(caret) # caret-pkg&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: lattice&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(e1071) # this is required in rstudio
# OVERALL SAME:
confumat &amp;lt;- hallmat1 # assign to confumat 

# For using caret confusionMatrix-function we need to spell out the reference and response table in this way:
Reference &amp;lt;- factor(rep(halls, times = c(sum(confumat[1,]),sum(confumat[2,]),sum(confumat[3,]),sum(confumat[4,]))), levels = halls)

Response &amp;lt;- factor(
c(
rep(halls, times = c(confumat[1,1], confumat[1,2], confumat[1,3], confumat[1,4])),
rep(halls, times = c(confumat[2,1], confumat[2,2], confumat[2,3], confumat[2,4])),
rep(halls, times = c(confumat[3,1], confumat[3,2], confumat[3,3], confumat[3,4])),
rep(halls, times = c(confumat[4,1], confumat[4,2], confumat[4,3], confumat[4,4]))),
levels = halls
)

xtab &amp;lt;- table(Response,Reference)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now, we are ready to run the analysis function from the caret-pckg:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#### ANALYSIS:
confusionMatrix(xtab, mode = &amp;quot;everything&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Confusion Matrix and Statistics
## 
##         Reference
## Response AC BP CP MH
##       AC 39 24 31 26
##       BP 17 39 33 28
##       CP 39 24 26 33
##       MH 25 33 30 33
## 
## Overall Statistics
##                                           
##                Accuracy : 0.2854          
##                  95% CI : (0.2454, 0.3281)
##     No Information Rate : 0.25            
##     P-Value [Acc &amp;gt; NIR] : 0.04246         
##                                           
##                   Kappa : 0.0472          
##                                           
##  Mcnemar&amp;#39;s Test P-Value : 0.66277         
## 
## Statistics by Class:
## 
##                      Class: AC Class: BP Class: CP Class: MH
## Sensitivity            0.32500   0.32500   0.21667   0.27500
## Specificity            0.77500   0.78333   0.73333   0.75556
## Pos Pred Value         0.32500   0.33333   0.21311   0.27273
## Neg Pred Value         0.77500   0.77686   0.73743   0.75766
## Precision              0.32500   0.33333   0.21311   0.27273
## Recall                 0.32500   0.32500   0.21667   0.27500
## F1                     0.32500   0.32911   0.21488   0.27386
## Prevalence             0.25000   0.25000   0.25000   0.25000
## Detection Rate         0.08125   0.08125   0.05417   0.06875
## Detection Prevalence   0.25000   0.24375   0.25417   0.25208
## Balanced Accuracy      0.55000   0.55417   0.47500   0.51528&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To recap, what these metrics mean, one may consult the &lt;a href=&#34;https://en.wikipedia.org/wiki/Confusion_matrix&#34;&gt;wikipedia page&lt;/a&gt; and also &lt;a href=&#34;https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2&#34;&gt;this&lt;/a&gt; and &lt;a href=&#34;https://www.datascienceblog.net/post/machine-learning/performance-measures-multi-class-problems/&#34;&gt;this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But, here is a very short summary:&lt;/p&gt;
&lt;p&gt;Terminology:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;condition positive (&lt;strong&gt;P&lt;/strong&gt;) : the number of real positive cases in the data&lt;/li&gt;
&lt;li&gt;condition negative (&lt;strong&gt;N&lt;/strong&gt;): the number of real negative cases in the data&lt;/li&gt;
&lt;li&gt;true positive (&lt;strong&gt;TP&lt;/strong&gt;), items that are correctly classified, i.e., “hit”&lt;/li&gt;
&lt;li&gt;true negative (&lt;strong&gt;TN&lt;/strong&gt;), items that are correctly classified as not belonging to the class, i.e. correct rejection&lt;/li&gt;
&lt;li&gt;false positive (&lt;strong&gt;FP&lt;/strong&gt;), items that are incorrectly perceived to belong to the class, i.e., false alarm (Type I error)&lt;/li&gt;
&lt;li&gt;false negative (&lt;strong&gt;FN&lt;/strong&gt;), items that are not perceived as belonging to the class but should have been; i.e., “miss” (Type II error)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The main metrics that may be interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;: The overall accuracy of the prediction (TP + TN) / P + N&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Recall&lt;/strong&gt;; &lt;strong&gt;sensitivity&lt;/strong&gt;; &lt;strong&gt;hit rate&lt;/strong&gt;; &lt;strong&gt;true positive rate&lt;/strong&gt; : the proportion of correct answers to total answers TP / P = TP / (TP + FN)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt; is the proportion of predictions that are correct from all “positive” predictions of that class TP / (TP + FP)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Recall and precision (and other metrics) can be calculated the following table that is generated separately for each hall :&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Prediction&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Hall 1&lt;/td&gt;
&lt;td&gt;Hall 234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Hall 1&lt;/td&gt;
&lt;td&gt;A (TP)&lt;/td&gt;
&lt;td&gt;B (FP)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Hall 234&lt;/td&gt;
&lt;td&gt;C (FN)&lt;/td&gt;
&lt;td&gt;D (TN)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;And for your reference (from caret-pckg documentation)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensitivity = A/(A+C)&lt;/li&gt;
&lt;li&gt;Specificity = D/(B+D)&lt;/li&gt;
&lt;li&gt;Prevalence = (A+C)/(A+B+C+D)&lt;/li&gt;
&lt;li&gt;Positive Predictive Value (PPV) (same as Precision) = (sensitivity * prevalence)/((sensitivity*prevalence) + ((1-specificity)*(1-prevalence)))&lt;/li&gt;
&lt;li&gt;Negative Preditive Value (NPV) = (specificity * (1-prevalence))/(((1-sensitivity)&lt;em&gt;prevalence) +
((specificity)&lt;/em&gt;(1-prevalence)))&lt;/li&gt;
&lt;li&gt;Detection Rate = A/(A+B+C+D)&lt;/li&gt;
&lt;li&gt;Detection Prevalence = (A+B)/(A+B+C+D)&lt;/li&gt;
&lt;li&gt;Balanced Accuracy = (sensitivity+specificity)/2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;And finally, here is an example of how to illustrate the results by plotting the confusion matrices with ggplot2. (xtab2 was generated the same way as xtab…)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;### PLOTTING WITH GGPLOT
# SAME plot
normvalue &amp;lt;- sum(hallmat1[1,]) # normalize
melted_xtab &amp;lt;- melt(round(xtab1/normvalue,2))
gsame &amp;lt;- ggplot(data = melted_xtab, aes(x=Response, y=Reference, fill=value),show.legend = F) + geom_tile(show.legend = F) + theme_minimal() +
geom_text(aes(Response, Reference, label = value), color = &amp;quot;black&amp;quot;, size = 3,show.legend = F) + ggtitle(&amp;#39;Same&amp;#39;)

# DIFF Plot
normvalue &amp;lt;- sum(hallmat2[1,])
melted_xtab &amp;lt;- melt(round(xtab2/normvalue,2))
gdiff &amp;lt;- ggplot(data = melted_xtab, aes(x=Response, y=Reference, fill=value),show.legend = F) + geom_tile(show.legend = F) + theme_minimal() +
geom_text(aes(Response, Reference, label = value), color = &amp;quot;black&amp;quot;, size = 3,show.legend = F) +ggtitle(&amp;#39;Different&amp;#39;)
#gdiff

grid.arrange(gsame,gdiff,nrow=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/2020-01-22-OnAnalysisOfCHMData/2020-01-22-OnAnalysisOfCHMData_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So there we are! And we will stop for now with this simulated dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps..&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Next steps..&lt;/h3&gt;
&lt;p&gt;Next steps would be to analyse the dataset in detail, investigate the differences between same and different excitation signals, evaluate whether there are some particular patterns emerging between the halls, and finally to provide an answer to the original question(s) about the human ability to match concert halls when listening to the same and different excitation signals?&lt;/p&gt;
&lt;p&gt;If all goes as planned, you’ll find the answer in a proper article sometime in the future and I’ll then link it here.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Cheers.&lt;/em&gt; :)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Non-post for testing the site</title>
      <link>/post/2019-11-09-test/2019-11-09-test/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019-11-09-test/2019-11-09-test/</guid>
      <description>


&lt;div id=&#34;r-markdown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R Markdown&lt;/h2&gt;
&lt;p&gt;HUHUHSDOHDUOH&lt;/p&gt;
&lt;!-- % This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;http://rmarkdown.rstudio.com&gt;. --&gt;
&lt;!-- When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: --&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(cars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      speed           dist       
##  Min.   : 4.0   Min.   :  2.00  
##  1st Qu.:12.0   1st Qu.: 26.00  
##  Median :15.0   Median : 36.00  
##  Mean   :15.4   Mean   : 42.98  
##  3rd Qu.:19.0   3rd Qu.: 56.00  
##  Max.   :25.0   Max.   :120.00&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;including-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Including Plots&lt;/h2&gt;
&lt;p&gt;You can also embed plots, for example:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../post/2019-11-09-test/2019-11-09-test_files/figure-html/pressure-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that the &lt;code&gt;echo = FALSE&lt;/code&gt; parameter was added to the code chunk to prevent printing of the R code that generated the plot.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
